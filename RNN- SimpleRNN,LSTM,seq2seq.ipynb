{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN,LSTM,seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQe3SZOHa5tw/slYhQFTHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinHeeeKang/Python_DeepLearning/blob/master/RNN-%20SimpleRNN%2CLSTM%2Cseq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XVOMClZA1ZG"
      },
      "source": [
        "# RNN\n",
        "- 순환신경망\n",
        "- simpleRNN_practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJCSe0afmaLH"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TrixyJl13bU"
      },
      "source": [
        "from tensorflow.keras.layers import SimpleRNN,Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtVzZX1A3Alh",
        "outputId": "c3ed54b8-7689-439b-fd34-287ea41a314b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imdb=tf.keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j9wRY6_3O5M",
        "outputId": "21d80e65-9267-4082-d991-927a30e0b7ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdzI2QYQ3xby"
      },
      "source": [
        "id_to_word=dict([(value,key) for key,value in word_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB3CpBTY3R88",
        "outputId": "4a6d91e2-ff68-436c-fb3e-c6aeb4717748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size = len(word_index)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpoXQB43WXB"
      },
      "source": [
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0 #공백\n",
        "word_index[\"<START>\"] = 1 #문장 시작\n",
        "word_index[\"<UNK>\"] = 2 #unknown 정보\n",
        "word_index[\"<UNUSED>\"] = 3 #사용하지않는 단어"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG-4yepO3aIu"
      },
      "source": [
        "def decode_review(text):\n",
        "  return ' '.join([id_to_word.get(i, '?') for i in text])#get() i가 없을때 ?출력 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa_nTheX5KEK",
        "outputId": "c85de492-2c1f-4c02-c8a2-3fed4e8211e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qZ5rllB3aBN",
        "outputId": "4a7fe0b0-2057-440c-e70a-6bb68df106a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nERM5c9t5tW9",
        "outputId": "71d1db24-0f16-4568-b83e-714ad8683493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_data[0]),len(train_data[1]),len(train_data[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189, 141)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zntugGEC52ML"
      },
      "source": [
        "# train,test확인해서 maxlen 길이 맞추기 \n",
        "maxlen=0\n",
        "for data in train_data:\n",
        "    if len(data)>maxlen:\n",
        "        maxlen=len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDDZDPT76V7l"
      },
      "source": [
        "for data in test_data:\n",
        "    if len(data)>maxlen:\n",
        "        maxlen=len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoH0IRl42oal",
        "outputId": "1effc942-2736-4c35-e01f-85bc4934ca83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "maxlen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2494"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cd9pPa22oWx"
      },
      "source": [
        "train_data=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    train_data,value=0,padding='pre',maxlen=maxlen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eyazdqq2oPZ"
      },
      "source": [
        "test_data=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    test_data,value=0,padding='pre',maxlen=maxlen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH4uLWO22oHE",
        "outputId": "9c8b40ad-4d2a-4204-9962-92f0b631e798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3vS7K6N2oDB",
        "outputId": "288a47ba-4a4c-47c7-ffdc-763231ef7666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kloP7TNf2n5Z"
      },
      "source": [
        "model= Sequential(\n",
        "    [\n",
        "    #  tf.keras.layers.Embedding(vocab_size)\n",
        "    SimpleRNN(units=126,input_shape=(None,maxlen)),# input이 많아서 은닉층(units)도 크게\n",
        "    Dense(16,activation='relu'),\n",
        "    Dense(1,activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqEHG_9M7xoE",
        "outputId": "d8ce39ad-a534-4d37-d9af-750a31c695fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 126)               330246    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2032      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 332,295\n",
            "Trainable params: 332,295\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJcI0zVS2ntB"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fj7xkrK8hZX"
      },
      "source": [
        "train_data=train_data[:,tf.newaxis,:]\n",
        "test_data=test_data[:,tf.newaxis,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB2n9SuS8tGa",
        "outputId": "ad1bbb75-bb6d-4692-a6e8-9601f53fe6a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 1, 2494), (25000, 1, 2494))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOU2JVCs2nku",
        "outputId": "4287011f-de6d-4665-8711-7993f297033d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#데이터를 3개로 맞춰줘야함\n",
        "history=model.fit(train_data,train_labels,\n",
        "                  epochs=20,\n",
        "                  batch_size=128,\n",
        "                  validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.7173 - accuracy: 0.5056 - val_loss: 0.7003 - val_accuracy: 0.4950\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.5128 - val_loss: 0.6954 - val_accuracy: 0.4994\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5135 - val_loss: 0.6952 - val_accuracy: 0.4988\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.5192 - val_loss: 0.6946 - val_accuracy: 0.5070\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.5214 - val_loss: 0.6949 - val_accuracy: 0.5142\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.5292 - val_loss: 0.6950 - val_accuracy: 0.5030\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6905 - accuracy: 0.5255 - val_loss: 0.6940 - val_accuracy: 0.5062\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6900 - accuracy: 0.5311 - val_loss: 0.6951 - val_accuracy: 0.5082\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.5264 - val_loss: 0.6963 - val_accuracy: 0.5068\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6901 - accuracy: 0.5270 - val_loss: 0.6955 - val_accuracy: 0.5136\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6905 - accuracy: 0.5250 - val_loss: 0.6957 - val_accuracy: 0.5040\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6890 - accuracy: 0.5296 - val_loss: 0.6954 - val_accuracy: 0.4996\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.5264 - val_loss: 0.6962 - val_accuracy: 0.5120\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6888 - accuracy: 0.5329 - val_loss: 0.6946 - val_accuracy: 0.5076\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.5326 - val_loss: 0.6948 - val_accuracy: 0.5094\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.5337 - val_loss: 0.6943 - val_accuracy: 0.5106\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.5343 - val_loss: 0.6967 - val_accuracy: 0.4994\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.5365 - val_loss: 0.6958 - val_accuracy: 0.5078\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.5314 - val_loss: 0.6952 - val_accuracy: 0.5088\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.5351 - val_loss: 0.6984 - val_accuracy: 0.5112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf7z1aA-1_rz"
      },
      "source": [
        "#RNN\n",
        "# model= Sequential(\n",
        "#     [\n",
        "#      SimpleRNN(units=16,input_shape=(None,)),\n",
        "#      Dense(8,activation='relu')\n",
        "#      Dense(1,activation='??')#풀려는 문제에 따라 달라짐\n",
        "#     ]\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7rw4YHD_R_c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEbOfKYpA5qa"
      },
      "source": [
        "#LSTM\n",
        "- Long Short-Term Memory\n",
        "- simpleRNN 보완\n",
        "- input 데이터가 많을때 중요한 정보가 마지막즈음엔 희석되어 있을 가능성이 크다  \n",
        " -> 이건 빼먹지말고 ㅇㅇ단계까지는 유지해라!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olD28CorJDHL"
      },
      "source": [
        "# LSTM을 사용한 문장생성\n",
        "- 애국가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U3eMVtgJGBy"
      },
      "source": [
        "text='''\n",
        "동해 물과 백두산이 마르고 닳도록\n",
        "하느님이 보우하사 우리나라 만세.\n",
        "무궁화 삼천리 화려 강산\n",
        "대한 사람, 대한으로 길이 보전하세.\n",
        "남산 위에 저 소나무, 철갑을 두른 듯\n",
        "바람 서리 불변함은 우리 기상일세.\n",
        "무궁화 삼천리 화려 강산\n",
        "대한 사람, 대한으로 길이 보전하세.\n",
        "가을 하늘 공활한데 높고 구름 없이\n",
        "밝은 달은 우리 가슴 일편단심일세.\n",
        "무궁화 삼천리 화려 강산\n",
        "대한 사람, 대한으로 길이 보전하세.\n",
        "이 기상과 이 맘으로 충성을 다하여\n",
        "괴로우나 즐거우나 나라 사랑하세.\n",
        "무궁화 삼천리 화려 강산\n",
        "대한 사람, 대한으로 길이 보전하세.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXZmRS2M3y5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riL_nBFhM329"
      },
      "source": [
        "#특수 문자 제거, 띄어쓰기 기준으로 쪼개기, indexing\n",
        "t = tf.keras.preprocessing.text.Tokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoHjeuGnM3tw"
      },
      "source": [
        "t.fit_on_texts([text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoVAbn_yNiuf",
        "outputId": "f817ad57-0f18-4b2b-c870-d77deb8cd8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size=len(t.word_index)+1 #빈값을 0으로 해주는데 word_index에 0이 없기때문에 +1해줌\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dSWa45QN3Be",
        "outputId": "1851bb0d-01cc-435e-9a2e-00bb442ae41f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'가슴': 40,\n",
              " '가을': 32,\n",
              " '강산': 4,\n",
              " '공활한데': 34,\n",
              " '괴로우나': 46,\n",
              " '구름': 36,\n",
              " '기상과': 42,\n",
              " '기상일세': 31,\n",
              " '길이': 8,\n",
              " '나라': 48,\n",
              " '남산': 21,\n",
              " '높고': 35,\n",
              " '다하여': 45,\n",
              " '달은': 39,\n",
              " '닳도록': 16,\n",
              " '대한': 5,\n",
              " '대한으로': 7,\n",
              " '동해': 12,\n",
              " '두른': 26,\n",
              " '듯': 27,\n",
              " '마르고': 15,\n",
              " '만세': 20,\n",
              " '맘으로': 43,\n",
              " '무궁화': 1,\n",
              " '물과': 13,\n",
              " '바람': 28,\n",
              " '밝은': 38,\n",
              " '백두산이': 14,\n",
              " '보우하사': 18,\n",
              " '보전하세': 9,\n",
              " '불변함은': 30,\n",
              " '사람': 6,\n",
              " '사랑하세': 49,\n",
              " '삼천리': 2,\n",
              " '서리': 29,\n",
              " '소나무': 24,\n",
              " '없이': 37,\n",
              " '우리': 10,\n",
              " '우리나라': 19,\n",
              " '위에': 22,\n",
              " '이': 11,\n",
              " '일편단심일세': 41,\n",
              " '저': 23,\n",
              " '즐거우나': 47,\n",
              " '철갑을': 25,\n",
              " '충성을': 44,\n",
              " '하느님이': 17,\n",
              " '하늘': 33,\n",
              " '화려': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCxCZEBvqEbf",
        "outputId": "a212315b-ab4b-4a2e-b5a6-e330a3067c2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "id_to_word=dict([(value,key) for key,value in t.word_index.items()])\n",
        "id_to_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: '무궁화',\n",
              " 2: '삼천리',\n",
              " 3: '화려',\n",
              " 4: '강산',\n",
              " 5: '대한',\n",
              " 6: '사람',\n",
              " 7: '대한으로',\n",
              " 8: '길이',\n",
              " 9: '보전하세',\n",
              " 10: '우리',\n",
              " 11: '이',\n",
              " 12: '동해',\n",
              " 13: '물과',\n",
              " 14: '백두산이',\n",
              " 15: '마르고',\n",
              " 16: '닳도록',\n",
              " 17: '하느님이',\n",
              " 18: '보우하사',\n",
              " 19: '우리나라',\n",
              " 20: '만세',\n",
              " 21: '남산',\n",
              " 22: '위에',\n",
              " 23: '저',\n",
              " 24: '소나무',\n",
              " 25: '철갑을',\n",
              " 26: '두른',\n",
              " 27: '듯',\n",
              " 28: '바람',\n",
              " 29: '서리',\n",
              " 30: '불변함은',\n",
              " 31: '기상일세',\n",
              " 32: '가을',\n",
              " 33: '하늘',\n",
              " 34: '공활한데',\n",
              " 35: '높고',\n",
              " 36: '구름',\n",
              " 37: '없이',\n",
              " 38: '밝은',\n",
              " 39: '달은',\n",
              " 40: '가슴',\n",
              " 41: '일편단심일세',\n",
              " 42: '기상과',\n",
              " 43: '맘으로',\n",
              " 44: '충성을',\n",
              " 45: '다하여',\n",
              " 46: '괴로우나',\n",
              " 47: '즐거우나',\n",
              " 48: '나라',\n",
              " 49: '사랑하세'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVOaqLxMOkvf"
      },
      "source": [
        "# for line in text_index:\n",
        "#     print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QueOTOpyN4Ni"
      },
      "source": [
        "sequences =list()\n",
        "for line in text.split('\\n'):\n",
        "    encoded = t.texts_to_sequences([line])[0] #texts_to_sequences 짜잘한 토근 제거해줌\n",
        "    # print(encoded)\n",
        "    #[12,13,14,15,16]\n",
        "    #[12,13]=>[14]\n",
        "    #[12,13,14]=>[15]\n",
        "    for i in range(1,len(encoded)):\n",
        "        sequence =encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "        # print(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd1kb_4MOols"
      },
      "source": [
        "maxlen=0\n",
        "for seq in sequences:\n",
        "    if len(seq)>maxlen:\n",
        "        maxlen= len(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPOjmxDdPoln"
      },
      "source": [
        "sequences=tf.keras.preprocessing.sequence.pad_sequences(sequences,value=0,maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYWSdoxoQa43",
        "outputId": "822d7dbf-a2a7-43e9-fda0-84d46bf92eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sequences[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0, 12, 13],\n",
              "       [ 0,  0,  0,  0, 12, 13, 14],\n",
              "       [ 0,  0,  0, 12, 13, 14, 15]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIrToHXFQdEV"
      },
      "source": [
        "X=sequences[:,:-1] \n",
        "y=sequences[:,-1] #끝 하나만"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ikt7OLQ6RY",
        "outputId": "baa133b7-9759-485e-c103-cc100346e08e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((62, 6), (62,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0KHZJ7BRArR",
        "outputId": "4e04aef7-7c00-4f1c-c2a5-abcf861f0fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0, 12],\n",
              "       [ 0,  0,  0,  0, 12, 13],\n",
              "       [ 0,  0,  0, 12, 13, 14],\n",
              "       [ 0,  0, 12, 13, 14, 15],\n",
              "       [ 0,  0,  0,  0,  0, 17]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya8en5_TRCB8",
        "outputId": "1f8ba676-cc86-4d89-f003-126a0c67cc74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 14, 15, 16, 18], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78aMsODgRC4Q"
      },
      "source": [
        "#one-hot\n",
        "y=tf.keras.utils.to_categorical(y,num_classes=vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXoofC24Rx0y",
        "outputId": "719185ab-cbd6-4877-ae3a-459b9d15ce91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHmOuXylRhcv"
      },
      "source": [
        "모델정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl6fLKc3RiWJ"
      },
      "source": [
        "# input -> embedding\n",
        "# LSTM->\n",
        "# Dense->softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pghLV2VmnTnm"
      },
      "source": [
        "model=tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Embedding(vocab_size,10),\n",
        "     tf.keras.layers.LSTM(128),\n",
        "     tf.keras.layers.Dense(vocab_size,activation='softmax')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v-7YasCntKs"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaqY2MNen5cN",
        "outputId": "a76d2e43-d564-433b-f904-58bbaba1c6a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history=model.fit(X,y,epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9109 - accuracy: 0.0645\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.9054 - accuracy: 0.0645\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8998 - accuracy: 0.0645\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8930 - accuracy: 0.0645\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8860 - accuracy: 0.0645\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8755 - accuracy: 0.0645\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.8641 - accuracy: 0.0645\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8478 - accuracy: 0.0645\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 3.8264 - accuracy: 0.0645\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.8002 - accuracy: 0.0645\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.7568 - accuracy: 0.0645\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.7180 - accuracy: 0.0645\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.6559 - accuracy: 0.0645\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5859 - accuracy: 0.0645\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5356 - accuracy: 0.0645\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5423 - accuracy: 0.0645\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5487 - accuracy: 0.0645\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5243 - accuracy: 0.0645\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4916 - accuracy: 0.0645\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4732 - accuracy: 0.0645\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4636 - accuracy: 0.1129\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4586 - accuracy: 0.0806\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4500 - accuracy: 0.0968\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4355 - accuracy: 0.0645\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4209 - accuracy: 0.0645\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4062 - accuracy: 0.0645\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3970 - accuracy: 0.0645\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3864 - accuracy: 0.0645\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.3782 - accuracy: 0.0645\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3625 - accuracy: 0.0645\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3505 - accuracy: 0.0645\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3350 - accuracy: 0.1452\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3220 - accuracy: 0.1290\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3085 - accuracy: 0.1290\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2907 - accuracy: 0.1452\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2771 - accuracy: 0.1613\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2594 - accuracy: 0.1935\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2433 - accuracy: 0.1452\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2227 - accuracy: 0.1935\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2033 - accuracy: 0.3548\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1850 - accuracy: 0.3226\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.1620 - accuracy: 0.4194\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1419 - accuracy: 0.2903\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1174 - accuracy: 0.2903\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0967 - accuracy: 0.2581\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0685 - accuracy: 0.2742\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0423 - accuracy: 0.3387\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.0132 - accuracy: 0.2903\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.9853 - accuracy: 0.2581\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9532 - accuracy: 0.1774\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.9221 - accuracy: 0.1290\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8849 - accuracy: 0.1290\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8518 - accuracy: 0.1290\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8099 - accuracy: 0.1452\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.7692 - accuracy: 0.2097\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7331 - accuracy: 0.2419\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.6918 - accuracy: 0.2742\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.6424 - accuracy: 0.3226\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.6058 - accuracy: 0.4032\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5548 - accuracy: 0.3548\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5145 - accuracy: 0.3548\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4751 - accuracy: 0.3871\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4272 - accuracy: 0.4032\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3784 - accuracy: 0.3871\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.3409 - accuracy: 0.4032\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.2992 - accuracy: 0.4032\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2682 - accuracy: 0.4194\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.2229 - accuracy: 0.4677\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1959 - accuracy: 0.4355\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1513 - accuracy: 0.4194\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1239 - accuracy: 0.4355\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0825 - accuracy: 0.5000\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.0496 - accuracy: 0.5806\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0371 - accuracy: 0.4677\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9902 - accuracy: 0.5645\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.5484\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9374 - accuracy: 0.5000\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9067 - accuracy: 0.5161\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8614 - accuracy: 0.5806\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8217 - accuracy: 0.6452\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7957 - accuracy: 0.5968\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7601 - accuracy: 0.6935\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7410 - accuracy: 0.6935\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7050 - accuracy: 0.6613\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6778 - accuracy: 0.6452\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6421 - accuracy: 0.6774\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6320 - accuracy: 0.6613\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5911 - accuracy: 0.6290\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5573 - accuracy: 0.6774\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5291 - accuracy: 0.6935\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5038 - accuracy: 0.7097\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4787 - accuracy: 0.6935\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4549 - accuracy: 0.7097\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4287 - accuracy: 0.7419\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4053 - accuracy: 0.7581\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3828 - accuracy: 0.7419\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3639 - accuracy: 0.7419\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3368 - accuracy: 0.7742\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.7419\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3019 - accuracy: 0.7419\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3020 - accuracy: 0.7258\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2629 - accuracy: 0.7742\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.2213 - accuracy: 0.7581\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2006 - accuracy: 0.7581\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1819 - accuracy: 0.7742\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1647 - accuracy: 0.7742\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 1.1447 - accuracy: 0.7903\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1294 - accuracy: 0.7903\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.7903\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0981 - accuracy: 0.7742\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.8065\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0553 - accuracy: 0.7903\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.7742\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0191 - accuracy: 0.8387\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.8065\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.7742\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9980 - accuracy: 0.7903\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9767 - accuracy: 0.8548\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9410 - accuracy: 0.8387\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9389 - accuracy: 0.8065\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9208 - accuracy: 0.8548\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9117 - accuracy: 0.8065\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9074 - accuracy: 0.8226\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9040 - accuracy: 0.7581\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8810 - accuracy: 0.8548\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.8710\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8602 - accuracy: 0.8548\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8511 - accuracy: 0.8548\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8299 - accuracy: 0.8548\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8181 - accuracy: 0.8387\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.8226\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.8548\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.8548\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7859 - accuracy: 0.9032\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.8387\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.9032\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.8710\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7541 - accuracy: 0.8548\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.8710\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7411 - accuracy: 0.9194\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.8548\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7030 - accuracy: 0.9355\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.8871\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.8871\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.9032\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.8710\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.8710\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.9032\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.8548\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.9032\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.9032\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.8710\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.9355\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.9355\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.9032\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.9355\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5756 - accuracy: 0.9032\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5708 - accuracy: 0.8871\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.9194\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.9355\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.9032\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.9194\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.9032\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.9032\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.9516\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.9194\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.9194\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.9355\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.9194\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.9194\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.9677\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.9677\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.9516\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.9355\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.9355\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.9194\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.9677\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.9677\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.9355\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.9677\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.9677\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.9516\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.9839\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.9677\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.9516\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9677\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.9677\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.9677\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.9677\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.9194\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.9677\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.9677\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.9677\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.9839\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.9839\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.9677\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.9677\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.9839\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.9839\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka3Bpt6VoRWR"
      },
      "source": [
        "- 학습된 모델\n",
        "- 현재 input (단어 하나 or 시작점 표시)\n",
        "- 생성하려는 문장의 길이\n",
        "- 걀과를 단어로 변환해주기 위한 TOKENIZER 함수화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2-mKoEVoC-H",
        "outputId": "2a1a2be8-c9dd-467a-c1d7-69798a234c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0, 12],\n",
              "       [ 0,  0,  0,  0, 12, 13]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5CEVTpRokTj",
        "outputId": "900dc094-c318-455a-d3b5-0267b7d6e4b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(X[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.07552057e-05, 2.58821274e-05, 6.64642919e-03, 2.55750562e-03,\n",
              "        2.13442356e-04, 3.15386606e-05, 4.27073725e-02, 4.97365510e-03,\n",
              "        1.25014770e-03, 1.52155160e-04, 2.54408619e-03, 1.63810272e-02,\n",
              "        2.35789630e-05, 2.16315597e-01, 1.22564770e-02, 2.81488377e-04,\n",
              "        1.99324772e-04, 5.29644531e-05, 2.78307218e-02, 2.19113124e-03,\n",
              "        2.73346814e-04, 2.55772502e-05, 1.81656539e-01, 3.65467034e-02,\n",
              "        8.10353784e-04, 5.92541655e-05, 3.58508873e-06, 1.38711684e-07,\n",
              "        2.19835638e-05, 9.96245220e-02, 2.22978052e-02, 3.95231982e-05,\n",
              "        3.22165761e-05, 4.61705476e-02, 6.06859056e-03, 1.93082771e-04,\n",
              "        5.33570255e-06, 1.09876214e-06, 1.62612832e-05, 9.50518698e-02,\n",
              "        6.20285791e-05, 3.11516828e-06, 1.26692265e-01, 3.07644514e-04,\n",
              "        8.10117945e-06, 4.97671181e-07, 2.90487078e-05, 4.66451719e-02,\n",
              "        6.65847911e-04, 3.26533300e-05],\n",
              "       [8.24494145e-06, 1.89094153e-05, 3.71399947e-05, 3.05986214e-06,\n",
              "        1.98530711e-06, 9.59580302e-06, 7.81558105e-04, 3.66012100e-04,\n",
              "        4.10932524e-04, 4.53757588e-04, 4.26415652e-02, 1.24015182e-01,\n",
              "        8.96002166e-06, 7.37600913e-03, 6.05044186e-01, 1.69253591e-02,\n",
              "        6.16992824e-04, 4.33362075e-05, 2.36898355e-04, 2.79327942e-04,\n",
              "        1.40368342e-04, 6.97150699e-06, 5.76735660e-03, 1.22495756e-01,\n",
              "        2.22978014e-02, 7.80145812e-04, 2.14688807e-05, 9.73647502e-07,\n",
              "        1.37653042e-05, 1.93924014e-03, 1.77723728e-02, 1.18272132e-04,\n",
              "        2.72873967e-05, 8.24187184e-04, 3.80211463e-03, 2.53578124e-04,\n",
              "        3.65327674e-06, 6.54614837e-07, 8.12920825e-06, 8.85834266e-03,\n",
              "        3.87261622e-04, 1.01559990e-05, 3.10680829e-03, 4.00279695e-03,\n",
              "        1.75111127e-05, 4.29793408e-06, 1.34746851e-05, 3.34510952e-03,\n",
              "        4.68331762e-03, 1.77760703e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHhnKEKkopMh",
        "outputId": "de2906ab-c7d1-4817-e78c-6188a19bd564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(model.predict(X[:5]),axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13, 14, 15, 16, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqxB7sUuoxhs",
        "outputId": "c6c6ed35-50e5-40f4-bf7e-8ff2ef20fcba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# '대한' 다음 단어를 생성하려면\n",
        "# '대한' => input모양에 맞게 변형\n",
        "encoded=t.texts_to_sequences(['대한'])\n",
        "print(encoded)\n",
        "encoded=tf.keras.preprocessing.sequence.pad_sequences(encoded,maxlen=maxlen)\n",
        "print(encoded)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5]]\n",
            "[[0 0 0 0 0 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR6kPVltpgcc",
        "outputId": "25137918-1126-4c8b-dc59-96c15edbb895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 5]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkOBM205picu"
      },
      "source": [
        "result=model.predict(encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_vKb6OTpm4w",
        "outputId": "796d918f-8204-4325-93a6-5e5905d4e991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(result,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ZusMgtpqbg",
        "outputId": "db1fe4e5-e66a-4eb5-9990-b90f98d39d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "id_to_word[np.argmax(result,axis=1)[0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사람'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqqJs5wysTS7",
        "outputId": "f3b19571-70ff-485e-db5e-e8b1b6064045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "maxlen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af5bjd7qqhcz",
        "outputId": "1d8fe2d6-1d89-460e-a698-b49c19290782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n=10\n",
        "current_input='대한'\n",
        "\n",
        "# result_str=''\n",
        "result_str=current_input\n",
        "for i in range(n):\n",
        "    print(current_input)\n",
        "    encoded=t.texts_to_sequences([current_input])\n",
        "    encoded=tf.keras.preprocessing.sequence.pad_sequences(encoded,maxlen=maxlen-1)    \n",
        "    print(encoded)\n",
        "\n",
        "    result=model.predict(encoded)\n",
        "    result_word=id_to_word[np.argmax(result, axis=1)[0]]\n",
        "    result_str += ' ' + result_word\n",
        "    current_input += ' ' + result_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "대한\n",
            "[[0 0 0 0 0 5]]\n",
            "대한 사람\n",
            "[[0 0 0 0 5 6]]\n",
            "대한 사람 대한으로\n",
            "[[0 0 0 5 6 7]]\n",
            "대한 사람 대한으로 길이\n",
            "[[0 0 5 6 7 8]]\n",
            "대한 사람 대한으로 길이 보전하세\n",
            "[[0 5 6 7 8 9]]\n",
            "대한 사람 대한으로 길이 보전하세 보전하세\n",
            "[[5 6 7 8 9 9]]\n",
            "대한 사람 대한으로 길이 보전하세 보전하세 보전하세\n",
            "[[6 7 8 9 9 9]]\n",
            "대한 사람 대한으로 길이 보전하세 보전하세 보전하세 보전하세\n",
            "[[7 8 9 9 9 9]]\n",
            "대한 사람 대한으로 길이 보전하세 보전하세 보전하세 보전하세 듯\n",
            "[[ 8  9  9  9  9 27]]\n",
            "대한 사람 대한으로 길이 보전하세 보전하세 보전하세 보전하세 듯 다하여\n",
            "[[ 9  9  9  9 27 45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua7R0bgVs6Lb",
        "outputId": "6ebe4fd7-a4e1-4a9f-d1d1-24a61eb90188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'대한 사람 대한으로 길이 보전하세 보전하세 보전하세 보전하세 듯 다하여 없이'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Q0OwyMtEFq"
      },
      "source": [
        "#함수화\n",
        "def sentence_generation(model,t,current_input,n):\n",
        "    result_str=current_input\n",
        "    for i in range(n):\n",
        "        encoded=t.texts_to_sequences([current_input])\n",
        "        encoded=tf.keras.preprocessing.sequence.pad_sequences(encoded,maxlen=maxlen-1)    \n",
        "\n",
        "        result=model.predict(encoded)\n",
        "        result_word=id_to_word[np.argmax(result, axis=1)[0]]\n",
        "        result_str += ' ' + result_word\n",
        "        current_input += ' ' + result_word\n",
        "\n",
        "    return result_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB24CRwfvXKO",
        "outputId": "e259c50b-f802-46e6-ebad-b62e643ccb52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sentence_generation(model,t,'기상',n=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기상 삼천리 삼천리 화려 화려\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0uE2Uf5vjqY",
        "outputId": "e15d285d-e5a7-46af-d54e-3da4daf1fd14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sentence_generation(model,t,'백두',n=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "백두 삼천리 삼천리 화려 화려\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCThYdBFvywZ",
        "outputId": "731666b2-6cf1-4547-878a-3542805e8dd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sentence_generation(model,t,'동해',n=7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동해 물과 백두산이 마르고 닳도록 다하여 듯 듯\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCjg9pe1v1i9",
        "outputId": "26b77229-5d11-4663-d496-28cc714e9299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sentence_generation(model,t,'하느님이',n=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "하느님이 보우하사 우리나라 만세 만세\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goGIwj10v5Xl",
        "outputId": "599637e9-beb2-4263-91ae-32299b1f61a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sentence_generation(model,t,'만세',n=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "만세 사람 사람 대한으로 보전하세\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXBfx6tOwnqw"
      },
      "source": [
        "# seq2seq\n",
        "- LSTM을 이용해 구현\n",
        "- encoder,decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk8q3xYj520v"
      },
      "source": [
        "- 덧셈 데이터 구성\n",
        "- encorder/decoder 정의\n",
        "- 학습\n",
        "- 평가(예측)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzkULa4gwpzi"
      },
      "source": [
        "#최대 세자리수끼리 합을 구하는 데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4xRWvj6L7g"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzVaw0CV6OJ9"
      },
      "source": [
        "# 99+1=>'9','9','+','1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqQag5ji6pam"
      },
      "source": [
        "num1=np.random.randint(0,1000)#0~999까지 수 중 랜덤생성\n",
        "num2=np.random.randint(0,1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBA0knDj6ptM"
      },
      "source": [
        "ans=num1+num2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSXGEFyv6pf-",
        "outputId": "6e841557-1706-471f-88ab-1111d9d2e27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num1,num2,ans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(585, 500, 1085)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWhRZMKw6pXC",
        "outputId": "cc405512-43a5-42cd-825e-0194abee42dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q_str=str(num1)+'+'+str(num2)\n",
        "print(q_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55+934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAL-1JyA7ApW",
        "outputId": "637a32eb-3df9-4e44-fe4e-7243e623bda1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(q_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5', '5', '+', '9', '3', '4']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFLAiEbY7DEu"
      },
      "source": [
        "word_to_id, id_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4g37lAx7NtN"
      },
      "source": [
        "#1\n",
        "word_to_id=dict([(str(key),value) for key,value in enumerate(range(10))])\n",
        "#2\n",
        "word_to_id={}\n",
        "for key,value in enumerate(range(10)):\n",
        "    word_to_id[str(key)]=value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z2mVYsd7ORh",
        "outputId": "3f380310-6a51-4ff5-9a5e-fa51f8f27e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_to_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+': 10,\n",
              " '0': 0,\n",
              " '1': 1,\n",
              " '2': 2,\n",
              " '3': 3,\n",
              " '4': 4,\n",
              " '5': 5,\n",
              " '6': 6,\n",
              " '7': 7,\n",
              " '8': 8,\n",
              " '9': 9,\n",
              " '_': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knRm-pot7OlQ"
      },
      "source": [
        "word_to_id['+']=len(word_to_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwVAjbwW7OXG"
      },
      "source": [
        "word_to_id['_']=len(word_to_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxNBSKoM7OGc"
      },
      "source": [
        "#1\n",
        "id_to_word=dict([(value,key) for key,value in word_to_id.items()])\n",
        "#2\n",
        "id_to_word={}\n",
        "for key,value in word_to_id.items():\n",
        "    id_to_word[value]=key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q-Uitj57Nqo",
        "outputId": "484587b3-7ed3-4bbc-e607-be23309d866b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "id_to_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '0',\n",
              " 1: '1',\n",
              " 2: '2',\n",
              " 3: '3',\n",
              " 4: '4',\n",
              " 5: '5',\n",
              " 6: '6',\n",
              " 7: '7',\n",
              " 8: '8',\n",
              " 9: '9',\n",
              " 10: '+',\n",
              " 11: '_'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4RbbGaL8RDN"
      },
      "source": [
        "#\n",
        "def get_sum_dict():\n",
        "    items=list(str(x) for x in range(10))\n",
        "    items.append('_')\n",
        "    items.append('+')\n",
        "\n",
        "    id_to_item={}\n",
        "    for idx,item in enumerate(items):\n",
        "        id_to_item[idx]=item\n",
        "    \n",
        "    item_to_id =dict([(value,key) for key,value in id_to_item.items()])\n",
        "\n",
        "    return id_to_item, item_to_id\n",
        "\n",
        "id_to_item,item_to_id=get_sum_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ0c24M999VE"
      },
      "source": [
        "def convert_item_to_id(items,item_to_id):\n",
        "    ids=list([item_to_id[item] for item in items])\n",
        "    return ids\n",
        "\n",
        "def convert_id_to_item(ids,id_to_item):\n",
        "    items=list([id_to_item[id] for id in ids])\n",
        "    return items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgpPta49Fp-"
      },
      "source": [
        "#x,y(label) 생성함수\n",
        "def sum_data_gen():\n",
        "    num1=np.random.randint(0,1000)\n",
        "    num2=np.random.randint(0,1000)  \n",
        "    ans=num1+num2\n",
        "    q_str=str(num1)+'+'+str(num2)\n",
        "    a_str='_'+str(ans).zfill(4) #4자리수로 맞춰라\n",
        "    return list(q_str), list(a_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxKwwLStNdkR",
        "outputId": "8a0d1933-480a-4558-d575-8b58cb05dd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sum_data_gen()[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_', '1', '0', '1', '3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAM6IuO09M3l"
      },
      "source": [
        "x,y=sum_data_gen()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjIb7Hf-3sb",
        "outputId": "3f5389f7-c56c-455b-e52d-5ce8ebe05d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['5', '4', '9', '+', '4', '2', '2'], ['_', '0', '9', '7', '1'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BsZfHAj-4zh"
      },
      "source": [
        "# convert_item_to_id()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-2yTejN-_5W"
      },
      "source": [
        "#만든 함수들을 활용해서 사용할 데이터셋을 생성 \n",
        "def get_dataset(data_num=100):\n",
        "    id_to_item,item_to_id = get_sum_dict()\n",
        "    xs=[]\n",
        "    ys=[]\n",
        "    for i in range(data_num):\n",
        "        x,y=sum_data_gen()\n",
        "        xs.append(convert_item_to_id(x,item_to_id))\n",
        "        ys.append(convert_item_to_id(y,item_to_id))\n",
        "    \n",
        "    return xs,ys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEs2iEl__ksT",
        "outputId": "b4c1afef-57d3-448d-d27a-543c694a2d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_dataset(data_num=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[1, 7, 3, 11, 7],\n",
              "  [1, 3, 1, 11, 9, 2, 0],\n",
              "  [1, 9, 5, 11, 6, 7, 8],\n",
              "  [9, 6, 3, 11, 4, 0, 6],\n",
              "  [2, 6, 4, 11, 1, 5, 8],\n",
              "  [5, 2, 0, 11, 6, 2, 9],\n",
              "  [6, 5, 3, 11, 2, 8, 0],\n",
              "  [3, 9, 7, 11, 9, 8, 4],\n",
              "  [3, 7, 6, 11, 6, 1, 6],\n",
              "  [8, 9, 0, 11, 6, 9, 9]],\n",
              " [[10, 0, 1, 8, 0],\n",
              "  [10, 1, 0, 5, 1],\n",
              "  [10, 0, 8, 7, 3],\n",
              "  [10, 1, 3, 6, 9],\n",
              "  [10, 0, 4, 2, 2],\n",
              "  [10, 1, 1, 4, 9],\n",
              "  [10, 0, 9, 3, 3],\n",
              "  [10, 1, 3, 8, 1],\n",
              "  [10, 0, 9, 9, 2],\n",
              "  [10, 1, 5, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4c5GdlGG-ed"
      },
      "source": [
        "train_x, train_y = get_dataset(data_num=20000)\n",
        "test_x, test_y = get_dataset(data_num=10000)\n",
        "id_to_item, item_to_id = get_sum_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pLYp0S4A_n1"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x6MCMUwBFL4"
      },
      "source": [
        "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdIvNa1YBYMw"
      },
      "source": [
        "#숫자+문자1 라서 똑같은거지 번역(한글->영어)과 같은 경우에는 양쪽 사이즈가 다름\n",
        "src_vocab_size=len(id_to_item)\n",
        "tar_vocab_size=len(item_to_id)#id_to_item?\n",
        "#one-hot인코딩할때 사용\n",
        "# vocab_size=len(id_to_item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRsUuhV7DyuD"
      },
      "source": [
        "train_x = pad_sequences(train_x, maxlen=7, padding='pre')\n",
        "test_x = pad_sequences(test_x, maxlen=7, padding='pre')\n",
        "train_y = pad_sequences(train_y, maxlen=5, padding='pre')\n",
        "test_y = pad_sequences(test_y, maxlen=5, padding='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0YUiktCNtuB"
      },
      "source": [
        "train_y_t=train_y[:,1:]\n",
        "test_y_t=test_y[:,1:]\n",
        "train_y_t = pad_sequences(train_y_t, maxlen=5, padding='pre')\n",
        "test_y_t = pad_sequences(test_y_t, maxlen=5, padding='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYNXMYglN2LW",
        "outputId": "81c82d09-b608-44c9-9ac0-6f8801dcfad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_y_t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yaVjuWhDNKQ"
      },
      "source": [
        "train_x = to_categorical(train_x, num_classes=vocab_size)\n",
        "test_x = to_categorical(test_x, num_classes=vocab_size)\n",
        "train_y = to_categorical(train_y, num_classes=vocab_size)\n",
        "test_y = to_categorical(test_y, num_classes=vocab_size)\n",
        "train_y_t= to_categorical(train_y_t, num_classes=vocab_size)\n",
        "test_y_t= to_categorical(test_y_t, num_classes=vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o180SQdODTs1",
        "outputId": "1e7786c9-de01-4b0b-9d46-bf16fa56e83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_x.shape, test_x.shape, train_y.shape, test_y.shape, train_y_t.shape, test_y_t.shape\n",
        "# ((20000, 7, 12),\n",
        "#  (10000, 7, 12),\n",
        "#  (20000, 5, 12),\n",
        "#  (10000, 5, 12),\n",
        "#  (20000, 5, 12),\n",
        "#  (10000, 5, 12))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 7, 12),\n",
              " (10000, 7, 12),\n",
              " (20000, 5, 12),\n",
              " (10000, 5, 12),\n",
              " (20000, 5, 12),\n",
              " (10000, 5, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PsQLOS3CXON"
      },
      "source": [
        "# Encoder \n",
        "# encoder_input = Embedding(vocab_size, 5,  input_length=7)\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(8, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYerce0vHSUj"
      },
      "source": [
        "#Decoder\n",
        "decoder_inputs=Input(shape=(None,tar_vocab_size))\n",
        "decoder_lstm=LSTM(8,return_state=True,return_sequences=True)\n",
        "#output,h,c자리인데 decoder의 h,c는 사용되지 않아서 _ 로\n",
        "decoder_outputs, _,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer=Dense(tar_vocab_size,activation='softmax')\n",
        "decoder_outputs=decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYM85NhDRr-z"
      },
      "source": [
        "#Model(input,output)\n",
        "model =Model([encoder_inputs,decoder_inputs],decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tac6H9xSoMX",
        "outputId": "d5419a81-f62b-457c-ff1b-24b549ca0a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 12)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 12)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 8), (None, 8 672         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 8), (N 672         input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 12)     108         lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,452\n",
            "Trainable params: 1,452\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EVU8s-nTpTW"
      },
      "source": [
        "# train_x.shape, test_x.shape, \n",
        "# train_y.shape, test_y.shape,\n",
        "# train_y_t.shape, test_y_t.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "204qfxDRS_9_"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy1mWG8cUN6X",
        "outputId": "112eacba-92f0-4552-8742-30954e866d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(x=[train_x,train_y],\n",
        "            y=train_y_t,\n",
        "            batch_size=512,\n",
        "            epochs=50,\n",
        "            validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 2.4461 - accuracy: 0.2699 - val_loss: 2.3936 - val_accuracy: 0.3967\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2.3283 - accuracy: 0.3946 - val_loss: 2.2385 - val_accuracy: 0.3808\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 2.1286 - accuracy: 0.3717 - val_loss: 2.0112 - val_accuracy: 0.3672\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.9166 - accuracy: 0.3787 - val_loss: 1.8285 - val_accuracy: 0.3879\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.7555 - accuracy: 0.4055 - val_loss: 1.6890 - val_accuracy: 0.4119\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.6303 - accuracy: 0.4223 - val_loss: 1.5731 - val_accuracy: 0.4315\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.5171 - accuracy: 0.4565 - val_loss: 1.4606 - val_accuracy: 0.5217\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.4055 - accuracy: 0.6033 - val_loss: 1.3491 - val_accuracy: 0.6359\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.2948 - accuracy: 0.6670 - val_loss: 1.2387 - val_accuracy: 0.7049\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.1850 - accuracy: 0.7319 - val_loss: 1.1294 - val_accuracy: 0.7704\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.0762 - accuracy: 0.8011 - val_loss: 1.0214 - val_accuracy: 0.8313\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.9698 - accuracy: 0.8663 - val_loss: 0.9173 - val_accuracy: 0.9209\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.8682 - accuracy: 0.9563 - val_loss: 0.8190 - val_accuracy: 0.9730\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.7733 - accuracy: 0.9790 - val_loss: 0.7281 - val_accuracy: 0.9857\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6865 - accuracy: 0.9897 - val_loss: 0.6458 - val_accuracy: 0.9939\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.9966 - val_loss: 0.5724 - val_accuracy: 0.9986\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.9990 - val_loss: 0.5075 - val_accuracy: 0.9991\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.9995 - val_loss: 0.4507 - val_accuracy: 0.9995\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.9998 - val_loss: 0.4011 - val_accuracy: 0.9999\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.9999 - val_loss: 0.3580 - val_accuracy: 0.9999\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3030 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2720 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1996 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1499 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5a0706dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pStWiUYUgKj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}